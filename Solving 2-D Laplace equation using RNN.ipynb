{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bed5a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import pandas as pd\n",
    "import csv\n",
    "from torch.utils.data import TensorDataset\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc32023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ffe2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0         1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
      "0            0  0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "1            0  0.000504    0.001004    0.001496    0.001974    0.002434   \n",
      "2            0  0.001011    0.002013    0.002998    0.003955    0.004878   \n",
      "3            0  0.001522    0.003030    0.004512    0.005954    0.007343   \n",
      "4            0  0.002039    0.004060    0.006045    0.007976    0.009838   \n",
      "5            0  0.002564    0.005106    0.007602    0.010032    0.012372   \n",
      "6            0  0.003100    0.006173    0.009191    0.012128    0.014958   \n",
      "7            0  0.003648    0.007265    0.010817    0.014274    0.017605   \n",
      "8            0  0.004212    0.008387    0.012488    0.016478    0.020323   \n",
      "9            0  0.004792    0.009543    0.014209    0.018750    0.023125   \n",
      "10           0  0.005393    0.010738    0.015988    0.021097    0.026020   \n",
      "11           0  0.006015    0.011976    0.017833    0.023531    0.029021   \n",
      "12           0  0.006661    0.013264    0.019749    0.026060    0.032141   \n",
      "13           0  0.007335    0.014605    0.021746    0.028695    0.035390   \n",
      "14           0  0.008038    0.016005    0.023831    0.031446    0.038783   \n",
      "15           0  0.008774    0.017470    0.026013    0.034325    0.042333   \n",
      "16           0  0.009545    0.019006    0.028299    0.037342    0.046055   \n",
      "17           0  0.010355    0.020619    0.030700    0.040510    0.049962   \n",
      "18           0  0.011207    0.022315    0.033225    0.043842    0.054071   \n",
      "19           0  0.012103    0.024100    0.035884    0.047350    0.058397   \n",
      "20           0  0.013049    0.025983    0.038687    0.051049    0.062959   \n",
      "21           0  0.014047    0.027970    0.041646    0.054954    0.067774   \n",
      "22           0  0.015102    0.030070    0.044773    0.059079    0.072861   \n",
      "23           0  0.016217    0.032290    0.048078    0.063441    0.078241   \n",
      "24           0  0.017397    0.034640    0.051577    0.068057    0.083934   \n",
      "25           0  0.018647    0.037129    0.055282    0.072945    0.089963   \n",
      "26           0  0.019971    0.039765    0.059208    0.078126    0.096351   \n",
      "27           0  0.021375    0.042561    0.063371    0.083618    0.103125   \n",
      "28           0  0.022865    0.045527    0.067786    0.089445    0.110310   \n",
      "29           0  0.024445    0.048674    0.072472    0.095628    0.117935   \n",
      "30           0  0.026123    0.052015    0.077447    0.102192    0.126030   \n",
      "31           0  0.027905    0.055564    0.082730    0.109162    0.134627   \n",
      "32           0  0.029798    0.059333    0.088342    0.116567    0.143759   \n",
      "33           0  0.031810    0.063338    0.094305    0.124436    0.153463   \n",
      "34           0  0.033948    0.067595    0.100643    0.132798    0.163776   \n",
      "35           0  0.036220    0.072120    0.107380    0.141688    0.174739   \n",
      "36           0  0.038637    0.076931    0.114543    0.151139    0.186394   \n",
      "37           0  0.041206    0.082047    0.122160    0.161190    0.198789   \n",
      "38           0  0.043939    0.087488    0.130261    0.171879    0.211971   \n",
      "39           0  0.046845    0.093275    0.138878    0.183248    0.225993   \n",
      "40           0  0.049937    0.099432    0.148044    0.195343    0.240909   \n",
      "41           0  0.053227    0.105982    0.157796    0.208211    0.256778   \n",
      "42           0  0.056727    0.112951    0.168172    0.221901    0.273662   \n",
      "43           0  0.060451    0.120366    0.179213    0.236469    0.291627   \n",
      "44           0  0.064414    0.128257    0.190962    0.251972    0.310745   \n",
      "45           0  0.068632    0.136654    0.203464    0.268469    0.331091   \n",
      "46           0  0.073120    0.145592    0.216771    0.286026    0.352743   \n",
      "47           0  0.077897    0.155103    0.230933    0.304713    0.375788   \n",
      "48           0  0.082982    0.165227    0.246007    0.324602    0.400317   \n",
      "49           0  0.088394    0.176003    0.262051    0.345772    0.426425   \n",
      "50           0  0.094155    0.187474    0.279129    0.368306    0.454215   \n",
      "\n",
      "    Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 91  \\\n",
      "0     0.000000    0.000000    0.000000    0.000000  ...     0.000000   \n",
      "1     0.002873    0.003287    0.003671    0.004023  ...     0.004014   \n",
      "2     0.005758    0.006587    0.007358    0.008063  ...     0.008045   \n",
      "3     0.008667    0.009915    0.011075    0.012136  ...     0.012109   \n",
      "4     0.011612    0.013283    0.014837    0.016259  ...     0.016223   \n",
      "5     0.014604    0.016706    0.018660    0.020449  ...     0.020404   \n",
      "6     0.017656    0.020197    0.022559    0.024722  ...     0.024669   \n",
      "7     0.020780    0.023770    0.026551    0.029096  ...     0.029035   \n",
      "8     0.023988    0.027441    0.030651    0.033589  ...     0.033519   \n",
      "9     0.027295    0.031223    0.034876    0.038219  ...     0.038141   \n",
      "10    0.030712    0.035133    0.039242    0.043004  ...     0.042919   \n",
      "11    0.034255    0.039185    0.043768    0.047964  ...     0.047872   \n",
      "12    0.037936    0.043397    0.048472    0.053119  ...     0.053020   \n",
      "13    0.041772    0.047784    0.053373    0.058489  ...     0.058384   \n",
      "14    0.045777    0.052365    0.058490    0.064096  ...     0.063985   \n",
      "15    0.049967    0.057158    0.063843    0.069962  ...     0.069846   \n",
      "16    0.054359    0.062182    0.069455    0.076111  ...     0.075990   \n",
      "17    0.058971    0.067457    0.075347    0.082568  ...     0.082442   \n",
      "18    0.063820    0.073005    0.081542    0.089357  ...     0.089227   \n",
      "19    0.068927    0.078846    0.088067    0.096507  ...     0.096373   \n",
      "20    0.074311    0.085005    0.094945    0.104044  ...     0.103908   \n",
      "21    0.079994    0.091506    0.102206    0.112000  ...     0.111861   \n",
      "22    0.085998    0.098374    0.109877    0.120406  ...     0.120265   \n",
      "23    0.092348    0.105636    0.117988    0.129294  ...     0.129152   \n",
      "24    0.099067    0.113322    0.126572    0.138700  ...     0.138558   \n",
      "25    0.106183    0.121461    0.135663    0.148662  ...     0.148519   \n",
      "26    0.113723    0.130086    0.145296    0.159218  ...     0.159075   \n",
      "27    0.121718    0.139231    0.155510    0.170409  ...     0.170268   \n",
      "28    0.130198    0.148931    0.166344    0.182281  ...     0.182141   \n",
      "29    0.139198    0.159225    0.177841    0.194879  ...     0.194741   \n",
      "30    0.148752    0.170154    0.190047    0.208254  ...     0.208119   \n",
      "31    0.158898    0.181759    0.203009    0.222458  ...     0.222325   \n",
      "32    0.169676    0.194088    0.216778    0.237546  ...     0.237417   \n",
      "33    0.181129    0.207188    0.231409    0.253578  ...     0.253453   \n",
      "34    0.193300    0.221111    0.246959    0.270617  ...     0.270497   \n",
      "35    0.206239    0.235911    0.263489    0.288730  ...     0.288615   \n",
      "36    0.219996    0.251646    0.281064    0.307987  ...     0.307878   \n",
      "37    0.234625    0.268380    0.299753    0.328466  ...     0.328363   \n",
      "38    0.250184    0.286176    0.319629    0.350246  ...     0.350149   \n",
      "39    0.266732    0.305105    0.340770    0.373412  ...     0.373322   \n",
      "40    0.284337    0.325242    0.363261    0.398056  ...     0.397973   \n",
      "41    0.303066    0.346665    0.387188    0.424274  ...     0.424199   \n",
      "42    0.322993    0.369459    0.412645    0.452170  ...     0.452102   \n",
      "43    0.344197    0.393713    0.439734    0.481853  ...     0.481793   \n",
      "44    0.366761    0.419523    0.468560    0.513440  ...     0.513388   \n",
      "45    0.390774    0.446989    0.499237    0.547054  ...     0.547011   \n",
      "46    0.416330    0.476221    0.531885    0.582829  ...     0.582794   \n",
      "47    0.443529    0.507332    0.566633    0.620904  ...     0.620878   \n",
      "48    0.472478    0.540446    0.603617    0.661430  ...     0.661413   \n",
      "49    0.503292    0.575692    0.642983    0.704566  ...     0.704557   \n",
      "50    0.536091    0.613210    0.684885    0.750481  ...     0.750481   \n",
      "\n",
      "    Unnamed: 92  Unnamed: 93  Unnamed: 94  Unnamed: 95  Unnamed: 96  \\\n",
      "0      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "1      0.003663     0.003280     0.002868     0.002430     0.001971   \n",
      "2      0.007342     0.006574     0.005748     0.004871     0.003950   \n",
      "3      0.011052     0.009896     0.008652     0.007331     0.005945   \n",
      "4      0.014806     0.013258     0.011592     0.009822     0.007965   \n",
      "5      0.018622     0.016675     0.014579     0.012353     0.010017   \n",
      "6      0.022514     0.020160     0.017626     0.014935     0.012111   \n",
      "7      0.026499     0.023728     0.020745     0.017578     0.014254   \n",
      "8      0.030592     0.027393     0.023949     0.020293     0.016456   \n",
      "9      0.034810     0.031170     0.027251     0.023091     0.018725   \n",
      "10     0.039171     0.035074     0.030665     0.025983     0.021070   \n",
      "11     0.043691     0.039121     0.034203     0.028981     0.023501   \n",
      "12     0.048389     0.043328     0.037881     0.032098     0.026028   \n",
      "13     0.053284     0.047711     0.041713     0.035344     0.028661   \n",
      "14     0.058396     0.052288     0.045715     0.038735     0.031410   \n",
      "15     0.063745     0.057077     0.049902     0.042283     0.034287   \n",
      "16     0.069352     0.062098     0.054291     0.046002     0.037303   \n",
      "17     0.075240     0.067370     0.058900     0.049907     0.040470   \n",
      "18     0.081433     0.072914     0.063748     0.054014     0.043800   \n",
      "19     0.087954     0.078753     0.068852     0.058339     0.047307   \n",
      "20     0.094831     0.084910     0.074235     0.062900     0.051005   \n",
      "21     0.102089     0.091409     0.079917     0.067714     0.054908   \n",
      "22     0.109758     0.098276     0.085920     0.072800     0.059033   \n",
      "23     0.117868     0.105537     0.092268     0.078179     0.063394   \n",
      "24     0.126452     0.113222     0.098987     0.083871     0.068010   \n",
      "25     0.135542     0.121362     0.106102     0.089900     0.072899   \n",
      "26     0.145176     0.129987     0.113643     0.096289     0.078079   \n",
      "27     0.155390     0.139132     0.121638     0.103063     0.083572   \n",
      "28     0.166226     0.148834     0.130119     0.110249     0.089399   \n",
      "29     0.177725     0.159129     0.139120     0.117875     0.095582   \n",
      "30     0.189933     0.170059     0.148676     0.125971     0.102147   \n",
      "31     0.202897     0.181667     0.158824     0.134569     0.109119   \n",
      "32     0.216670     0.193998     0.169604     0.143703     0.116525   \n",
      "33     0.231304     0.207101     0.181059     0.153408     0.124395   \n",
      "34     0.246858     0.221027     0.193233     0.163723     0.132759   \n",
      "35     0.263392     0.235831     0.206175     0.174688     0.141650   \n",
      "36     0.280972     0.251570     0.219935     0.186346     0.151103   \n",
      "37     0.299666     0.268308     0.234567     0.198744     0.161156   \n",
      "38     0.319547     0.286108     0.250129     0.211929     0.171847   \n",
      "39     0.340694     0.305042     0.266682     0.225953     0.183219   \n",
      "40     0.363191     0.325184     0.284290     0.240872     0.195316   \n",
      "41     0.387124     0.346612     0.303023     0.256744     0.208186   \n",
      "42     0.412588     0.369411     0.322955     0.273632     0.221879   \n",
      "43     0.439684     0.393671     0.344164     0.291601     0.236450   \n",
      "44     0.468517     0.419486     0.366732     0.310722     0.251954   \n",
      "45     0.499201     0.446959     0.390749     0.331071     0.268455   \n",
      "46     0.531856     0.476196     0.416310     0.352728     0.286015   \n",
      "47     0.566611     0.507314     0.443514     0.375777     0.304704   \n",
      "48     0.603602     0.540434     0.472468     0.400309     0.324596   \n",
      "49     0.642975     0.575686     0.503287     0.426421     0.345769   \n",
      "50     0.684885     0.613210     0.536091     0.454215     0.368306   \n",
      "\n",
      "    Unnamed: 97  Unnamed: 98  Unnamed: 99  Unnamed: 100  \n",
      "0      0.000000     0.000000     0.000000  0.000000e+00  \n",
      "1      0.001494     0.001003     0.000504  2.001140e-18  \n",
      "2      0.002994     0.002011     0.001010  4.010183e-18  \n",
      "3      0.004506     0.003026     0.001520  6.035062e-18  \n",
      "4      0.006037     0.004055     0.002036  8.083775e-18  \n",
      "5      0.007592     0.005100     0.002561  1.016441e-17  \n",
      "6      0.009179     0.006165     0.003097  1.228519e-17  \n",
      "7      0.010803     0.007256     0.003645  1.445448e-17  \n",
      "8      0.012472     0.008377     0.004207  1.668086e-17  \n",
      "9      0.014192     0.009532     0.004788  1.897311e-17  \n",
      "10     0.015969     0.010726     0.005387  2.134029e-17  \n",
      "11     0.017812     0.011964     0.006009  2.379174e-17  \n",
      "12     0.019727     0.013250     0.006655  2.633715e-17  \n",
      "13     0.021722     0.014590     0.007328  2.898658e-17  \n",
      "14     0.023806     0.015990     0.008031  3.175047e-17  \n",
      "15     0.025986     0.017454     0.008766  3.463975e-17  \n",
      "16     0.028272     0.018989     0.009537  3.766583e-17  \n",
      "17     0.030672     0.020601     0.010347  4.084065e-17  \n",
      "18     0.033196     0.022297     0.011198  4.417676e-17  \n",
      "19     0.035854     0.024082     0.012095  4.768733e-17  \n",
      "20     0.038657     0.025964     0.013040  5.138622e-17  \n",
      "21     0.041615     0.027951     0.014038  5.528805e-17  \n",
      "22     0.044741     0.030050     0.015093  5.940822e-17  \n",
      "23     0.048046     0.032271     0.016208  6.376299e-17  \n",
      "24     0.051544     0.034620     0.017388  6.836958e-17  \n",
      "25     0.055249     0.037108     0.018637  7.324617e-17  \n",
      "26     0.059175     0.039745     0.019962  7.841201e-17  \n",
      "27     0.063338     0.042541     0.021366  8.388752e-17  \n",
      "28     0.067754     0.045507     0.022855  8.969431e-17  \n",
      "29     0.072441     0.048655     0.024436  9.585532e-17  \n",
      "30     0.077416     0.051996     0.026114  1.023949e-16  \n",
      "31     0.082700     0.055545     0.027897  1.093388e-16  \n",
      "32     0.088312     0.059315     0.029790  1.167145e-16  \n",
      "33     0.094276     0.063321     0.031802  1.245512e-16  \n",
      "34     0.100615     0.067578     0.033940  1.328797e-16  \n",
      "35     0.107354     0.072104     0.036213  1.417329e-16  \n",
      "36     0.114518     0.076915     0.038629  1.511459e-16  \n",
      "37     0.122136     0.082032     0.041199  1.611558e-16  \n",
      "38     0.130239     0.087474     0.043932  1.718021e-16  \n",
      "39     0.138857     0.093262     0.046839  1.831269e-16  \n",
      "40     0.148025     0.099420     0.049932  1.951749e-16  \n",
      "41     0.157779     0.105971     0.053222  2.079937e-16  \n",
      "42     0.168156     0.112941     0.056722  2.216338e-16  \n",
      "43     0.179199     0.120357     0.060447  2.361492e-16  \n",
      "44     0.190950     0.128249     0.064411  2.515972e-16  \n",
      "45     0.203454     0.136648     0.068629  2.680388e-16  \n",
      "46     0.216763     0.145587     0.073118  2.855389e-16  \n",
      "47     0.230927     0.155100     0.077896  3.041667e-16  \n",
      "48     0.246002     0.165225     0.082981  3.239956e-16  \n",
      "49     0.262049     0.176002     0.088393  3.451041e-16  \n",
      "50     0.279129     0.187474     0.094155  3.675754e-16  \n",
      "\n",
      "[51 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'F:\\Research\\smart photonics\\projects\\case study\\2-d laplace equation solution\\data.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "574299b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "din=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceb83991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 91</th>\n",
       "      <th>Unnamed: 92</th>\n",
       "      <th>Unnamed: 93</th>\n",
       "      <th>Unnamed: 94</th>\n",
       "      <th>Unnamed: 95</th>\n",
       "      <th>Unnamed: 96</th>\n",
       "      <th>Unnamed: 97</th>\n",
       "      <th>Unnamed: 98</th>\n",
       "      <th>Unnamed: 99</th>\n",
       "      <th>Unnamed: 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>2.001140e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>4.010183e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.011052</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>6.035062e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.009838</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016223</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>8.083775e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.016706</td>\n",
       "      <td>0.018660</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020404</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.007592</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>1.016441e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.020197</td>\n",
       "      <td>0.022559</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>0.022514</td>\n",
       "      <td>0.020160</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>1.228519e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.017605</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.026551</td>\n",
       "      <td>0.029096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029035</td>\n",
       "      <td>0.026499</td>\n",
       "      <td>0.023728</td>\n",
       "      <td>0.020745</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>1.445448e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.027441</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.033589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>0.027393</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>0.012472</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>1.668086e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.009543</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>0.031223</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>0.038219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038141</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>0.027251</td>\n",
       "      <td>0.023091</td>\n",
       "      <td>0.018725</td>\n",
       "      <td>0.014192</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>0.004788</td>\n",
       "      <td>1.897311e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>0.026020</td>\n",
       "      <td>0.030712</td>\n",
       "      <td>0.035133</td>\n",
       "      <td>0.039242</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042919</td>\n",
       "      <td>0.039171</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.015969</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>2.134029e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.017833</td>\n",
       "      <td>0.023531</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.034255</td>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.047964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047872</td>\n",
       "      <td>0.043691</td>\n",
       "      <td>0.039121</td>\n",
       "      <td>0.034203</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>2.379174e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.026060</td>\n",
       "      <td>0.032141</td>\n",
       "      <td>0.037936</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>0.048389</td>\n",
       "      <td>0.043328</td>\n",
       "      <td>0.037881</td>\n",
       "      <td>0.032098</td>\n",
       "      <td>0.026028</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>2.633715e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.021746</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.047784</td>\n",
       "      <td>0.053373</td>\n",
       "      <td>0.058489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058384</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.047711</td>\n",
       "      <td>0.041713</td>\n",
       "      <td>0.035344</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>2.898658e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>0.038783</td>\n",
       "      <td>0.045777</td>\n",
       "      <td>0.052365</td>\n",
       "      <td>0.058490</td>\n",
       "      <td>0.064096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063985</td>\n",
       "      <td>0.058396</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>3.175047e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.026013</td>\n",
       "      <td>0.034325</td>\n",
       "      <td>0.042333</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.057158</td>\n",
       "      <td>0.063843</td>\n",
       "      <td>0.069962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069846</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.057077</td>\n",
       "      <td>0.049902</td>\n",
       "      <td>0.042283</td>\n",
       "      <td>0.034287</td>\n",
       "      <td>0.025986</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.008766</td>\n",
       "      <td>3.463975e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.028299</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.046055</td>\n",
       "      <td>0.054359</td>\n",
       "      <td>0.062182</td>\n",
       "      <td>0.069455</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075990</td>\n",
       "      <td>0.069352</td>\n",
       "      <td>0.062098</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>0.046002</td>\n",
       "      <td>0.037303</td>\n",
       "      <td>0.028272</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>3.766583e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.040510</td>\n",
       "      <td>0.049962</td>\n",
       "      <td>0.058971</td>\n",
       "      <td>0.067457</td>\n",
       "      <td>0.075347</td>\n",
       "      <td>0.082568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082442</td>\n",
       "      <td>0.075240</td>\n",
       "      <td>0.067370</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>0.040470</td>\n",
       "      <td>0.030672</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>4.084065e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.033225</td>\n",
       "      <td>0.043842</td>\n",
       "      <td>0.054071</td>\n",
       "      <td>0.063820</td>\n",
       "      <td>0.073005</td>\n",
       "      <td>0.081542</td>\n",
       "      <td>0.089357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089227</td>\n",
       "      <td>0.081433</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.063748</td>\n",
       "      <td>0.054014</td>\n",
       "      <td>0.043800</td>\n",
       "      <td>0.033196</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>4.417676e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.035884</td>\n",
       "      <td>0.047350</td>\n",
       "      <td>0.058397</td>\n",
       "      <td>0.068927</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.088067</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.087954</td>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.068852</td>\n",
       "      <td>0.058339</td>\n",
       "      <td>0.047307</td>\n",
       "      <td>0.035854</td>\n",
       "      <td>0.024082</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>4.768733e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013049</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.038687</td>\n",
       "      <td>0.051049</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.074311</td>\n",
       "      <td>0.085005</td>\n",
       "      <td>0.094945</td>\n",
       "      <td>0.104044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103908</td>\n",
       "      <td>0.094831</td>\n",
       "      <td>0.084910</td>\n",
       "      <td>0.074235</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.051005</td>\n",
       "      <td>0.038657</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>5.138622e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>0.027970</td>\n",
       "      <td>0.041646</td>\n",
       "      <td>0.054954</td>\n",
       "      <td>0.067774</td>\n",
       "      <td>0.079994</td>\n",
       "      <td>0.091506</td>\n",
       "      <td>0.102206</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111861</td>\n",
       "      <td>0.102089</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.067714</td>\n",
       "      <td>0.054908</td>\n",
       "      <td>0.041615</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>5.528805e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.030070</td>\n",
       "      <td>0.044773</td>\n",
       "      <td>0.059079</td>\n",
       "      <td>0.072861</td>\n",
       "      <td>0.085998</td>\n",
       "      <td>0.098374</td>\n",
       "      <td>0.109877</td>\n",
       "      <td>0.120406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120265</td>\n",
       "      <td>0.109758</td>\n",
       "      <td>0.098276</td>\n",
       "      <td>0.085920</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.059033</td>\n",
       "      <td>0.044741</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>5.940822e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016217</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>0.078241</td>\n",
       "      <td>0.092348</td>\n",
       "      <td>0.105636</td>\n",
       "      <td>0.117988</td>\n",
       "      <td>0.129294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129152</td>\n",
       "      <td>0.117868</td>\n",
       "      <td>0.105537</td>\n",
       "      <td>0.092268</td>\n",
       "      <td>0.078179</td>\n",
       "      <td>0.063394</td>\n",
       "      <td>0.048046</td>\n",
       "      <td>0.032271</td>\n",
       "      <td>0.016208</td>\n",
       "      <td>6.376299e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017397</td>\n",
       "      <td>0.034640</td>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.068057</td>\n",
       "      <td>0.083934</td>\n",
       "      <td>0.099067</td>\n",
       "      <td>0.113322</td>\n",
       "      <td>0.126572</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138558</td>\n",
       "      <td>0.126452</td>\n",
       "      <td>0.113222</td>\n",
       "      <td>0.098987</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>0.034620</td>\n",
       "      <td>0.017388</td>\n",
       "      <td>6.836958e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018647</td>\n",
       "      <td>0.037129</td>\n",
       "      <td>0.055282</td>\n",
       "      <td>0.072945</td>\n",
       "      <td>0.089963</td>\n",
       "      <td>0.106183</td>\n",
       "      <td>0.121461</td>\n",
       "      <td>0.135663</td>\n",
       "      <td>0.148662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148519</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.121362</td>\n",
       "      <td>0.106102</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.072899</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.037108</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>7.324617e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.039765</td>\n",
       "      <td>0.059208</td>\n",
       "      <td>0.078126</td>\n",
       "      <td>0.096351</td>\n",
       "      <td>0.113723</td>\n",
       "      <td>0.130086</td>\n",
       "      <td>0.145296</td>\n",
       "      <td>0.159218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159075</td>\n",
       "      <td>0.145176</td>\n",
       "      <td>0.129987</td>\n",
       "      <td>0.113643</td>\n",
       "      <td>0.096289</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.059175</td>\n",
       "      <td>0.039745</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>7.841201e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.042561</td>\n",
       "      <td>0.063371</td>\n",
       "      <td>0.083618</td>\n",
       "      <td>0.103125</td>\n",
       "      <td>0.121718</td>\n",
       "      <td>0.139231</td>\n",
       "      <td>0.155510</td>\n",
       "      <td>0.170409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170268</td>\n",
       "      <td>0.155390</td>\n",
       "      <td>0.139132</td>\n",
       "      <td>0.121638</td>\n",
       "      <td>0.103063</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.063338</td>\n",
       "      <td>0.042541</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>8.388752e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.045527</td>\n",
       "      <td>0.067786</td>\n",
       "      <td>0.089445</td>\n",
       "      <td>0.110310</td>\n",
       "      <td>0.130198</td>\n",
       "      <td>0.148931</td>\n",
       "      <td>0.166344</td>\n",
       "      <td>0.182281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182141</td>\n",
       "      <td>0.166226</td>\n",
       "      <td>0.148834</td>\n",
       "      <td>0.130119</td>\n",
       "      <td>0.110249</td>\n",
       "      <td>0.089399</td>\n",
       "      <td>0.067754</td>\n",
       "      <td>0.045507</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>8.969431e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.048674</td>\n",
       "      <td>0.072472</td>\n",
       "      <td>0.095628</td>\n",
       "      <td>0.117935</td>\n",
       "      <td>0.139198</td>\n",
       "      <td>0.159225</td>\n",
       "      <td>0.177841</td>\n",
       "      <td>0.194879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194741</td>\n",
       "      <td>0.177725</td>\n",
       "      <td>0.159129</td>\n",
       "      <td>0.139120</td>\n",
       "      <td>0.117875</td>\n",
       "      <td>0.095582</td>\n",
       "      <td>0.072441</td>\n",
       "      <td>0.048655</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>9.585532e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.052015</td>\n",
       "      <td>0.077447</td>\n",
       "      <td>0.102192</td>\n",
       "      <td>0.126030</td>\n",
       "      <td>0.148752</td>\n",
       "      <td>0.170154</td>\n",
       "      <td>0.190047</td>\n",
       "      <td>0.208254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208119</td>\n",
       "      <td>0.189933</td>\n",
       "      <td>0.170059</td>\n",
       "      <td>0.148676</td>\n",
       "      <td>0.125971</td>\n",
       "      <td>0.102147</td>\n",
       "      <td>0.077416</td>\n",
       "      <td>0.051996</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>1.023949e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027905</td>\n",
       "      <td>0.055564</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.109162</td>\n",
       "      <td>0.134627</td>\n",
       "      <td>0.158898</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.203009</td>\n",
       "      <td>0.222458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222325</td>\n",
       "      <td>0.202897</td>\n",
       "      <td>0.181667</td>\n",
       "      <td>0.158824</td>\n",
       "      <td>0.134569</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.055545</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>1.093388e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029798</td>\n",
       "      <td>0.059333</td>\n",
       "      <td>0.088342</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.143759</td>\n",
       "      <td>0.169676</td>\n",
       "      <td>0.194088</td>\n",
       "      <td>0.216778</td>\n",
       "      <td>0.237546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237417</td>\n",
       "      <td>0.216670</td>\n",
       "      <td>0.193998</td>\n",
       "      <td>0.169604</td>\n",
       "      <td>0.143703</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.088312</td>\n",
       "      <td>0.059315</td>\n",
       "      <td>0.029790</td>\n",
       "      <td>1.167145e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031810</td>\n",
       "      <td>0.063338</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.124436</td>\n",
       "      <td>0.153463</td>\n",
       "      <td>0.181129</td>\n",
       "      <td>0.207188</td>\n",
       "      <td>0.231409</td>\n",
       "      <td>0.253578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253453</td>\n",
       "      <td>0.231304</td>\n",
       "      <td>0.207101</td>\n",
       "      <td>0.181059</td>\n",
       "      <td>0.153408</td>\n",
       "      <td>0.124395</td>\n",
       "      <td>0.094276</td>\n",
       "      <td>0.063321</td>\n",
       "      <td>0.031802</td>\n",
       "      <td>1.245512e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033948</td>\n",
       "      <td>0.067595</td>\n",
       "      <td>0.100643</td>\n",
       "      <td>0.132798</td>\n",
       "      <td>0.163776</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.246959</td>\n",
       "      <td>0.270617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270497</td>\n",
       "      <td>0.246858</td>\n",
       "      <td>0.221027</td>\n",
       "      <td>0.193233</td>\n",
       "      <td>0.163723</td>\n",
       "      <td>0.132759</td>\n",
       "      <td>0.100615</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.033940</td>\n",
       "      <td>1.328797e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036220</td>\n",
       "      <td>0.072120</td>\n",
       "      <td>0.107380</td>\n",
       "      <td>0.141688</td>\n",
       "      <td>0.174739</td>\n",
       "      <td>0.206239</td>\n",
       "      <td>0.235911</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.288730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288615</td>\n",
       "      <td>0.263392</td>\n",
       "      <td>0.235831</td>\n",
       "      <td>0.206175</td>\n",
       "      <td>0.174688</td>\n",
       "      <td>0.141650</td>\n",
       "      <td>0.107354</td>\n",
       "      <td>0.072104</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>1.417329e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0.038637</td>\n",
       "      <td>0.076931</td>\n",
       "      <td>0.114543</td>\n",
       "      <td>0.151139</td>\n",
       "      <td>0.186394</td>\n",
       "      <td>0.219996</td>\n",
       "      <td>0.251646</td>\n",
       "      <td>0.281064</td>\n",
       "      <td>0.307987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307878</td>\n",
       "      <td>0.280972</td>\n",
       "      <td>0.251570</td>\n",
       "      <td>0.219935</td>\n",
       "      <td>0.186346</td>\n",
       "      <td>0.151103</td>\n",
       "      <td>0.114518</td>\n",
       "      <td>0.076915</td>\n",
       "      <td>0.038629</td>\n",
       "      <td>1.511459e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0.041206</td>\n",
       "      <td>0.082047</td>\n",
       "      <td>0.122160</td>\n",
       "      <td>0.161190</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>0.234625</td>\n",
       "      <td>0.268380</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>0.328466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328363</td>\n",
       "      <td>0.299666</td>\n",
       "      <td>0.268308</td>\n",
       "      <td>0.234567</td>\n",
       "      <td>0.198744</td>\n",
       "      <td>0.161156</td>\n",
       "      <td>0.122136</td>\n",
       "      <td>0.082032</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>1.611558e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.087488</td>\n",
       "      <td>0.130261</td>\n",
       "      <td>0.171879</td>\n",
       "      <td>0.211971</td>\n",
       "      <td>0.250184</td>\n",
       "      <td>0.286176</td>\n",
       "      <td>0.319629</td>\n",
       "      <td>0.350246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350149</td>\n",
       "      <td>0.319547</td>\n",
       "      <td>0.286108</td>\n",
       "      <td>0.250129</td>\n",
       "      <td>0.211929</td>\n",
       "      <td>0.171847</td>\n",
       "      <td>0.130239</td>\n",
       "      <td>0.087474</td>\n",
       "      <td>0.043932</td>\n",
       "      <td>1.718021e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>0.093275</td>\n",
       "      <td>0.138878</td>\n",
       "      <td>0.183248</td>\n",
       "      <td>0.225993</td>\n",
       "      <td>0.266732</td>\n",
       "      <td>0.305105</td>\n",
       "      <td>0.340770</td>\n",
       "      <td>0.373412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373322</td>\n",
       "      <td>0.340694</td>\n",
       "      <td>0.305042</td>\n",
       "      <td>0.266682</td>\n",
       "      <td>0.225953</td>\n",
       "      <td>0.183219</td>\n",
       "      <td>0.138857</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>0.046839</td>\n",
       "      <td>1.831269e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0.049937</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.148044</td>\n",
       "      <td>0.195343</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>0.284337</td>\n",
       "      <td>0.325242</td>\n",
       "      <td>0.363261</td>\n",
       "      <td>0.398056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397973</td>\n",
       "      <td>0.363191</td>\n",
       "      <td>0.325184</td>\n",
       "      <td>0.284290</td>\n",
       "      <td>0.240872</td>\n",
       "      <td>0.195316</td>\n",
       "      <td>0.148025</td>\n",
       "      <td>0.099420</td>\n",
       "      <td>0.049932</td>\n",
       "      <td>1.951749e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053227</td>\n",
       "      <td>0.105982</td>\n",
       "      <td>0.157796</td>\n",
       "      <td>0.208211</td>\n",
       "      <td>0.256778</td>\n",
       "      <td>0.303066</td>\n",
       "      <td>0.346665</td>\n",
       "      <td>0.387188</td>\n",
       "      <td>0.424274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424199</td>\n",
       "      <td>0.387124</td>\n",
       "      <td>0.346612</td>\n",
       "      <td>0.303023</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.208186</td>\n",
       "      <td>0.157779</td>\n",
       "      <td>0.105971</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>2.079937e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0.056727</td>\n",
       "      <td>0.112951</td>\n",
       "      <td>0.168172</td>\n",
       "      <td>0.221901</td>\n",
       "      <td>0.273662</td>\n",
       "      <td>0.322993</td>\n",
       "      <td>0.369459</td>\n",
       "      <td>0.412645</td>\n",
       "      <td>0.452170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452102</td>\n",
       "      <td>0.412588</td>\n",
       "      <td>0.369411</td>\n",
       "      <td>0.322955</td>\n",
       "      <td>0.273632</td>\n",
       "      <td>0.221879</td>\n",
       "      <td>0.168156</td>\n",
       "      <td>0.112941</td>\n",
       "      <td>0.056722</td>\n",
       "      <td>2.216338e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0.060451</td>\n",
       "      <td>0.120366</td>\n",
       "      <td>0.179213</td>\n",
       "      <td>0.236469</td>\n",
       "      <td>0.291627</td>\n",
       "      <td>0.344197</td>\n",
       "      <td>0.393713</td>\n",
       "      <td>0.439734</td>\n",
       "      <td>0.481853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481793</td>\n",
       "      <td>0.439684</td>\n",
       "      <td>0.393671</td>\n",
       "      <td>0.344164</td>\n",
       "      <td>0.291601</td>\n",
       "      <td>0.236450</td>\n",
       "      <td>0.179199</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.060447</td>\n",
       "      <td>2.361492e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0.064414</td>\n",
       "      <td>0.128257</td>\n",
       "      <td>0.190962</td>\n",
       "      <td>0.251972</td>\n",
       "      <td>0.310745</td>\n",
       "      <td>0.366761</td>\n",
       "      <td>0.419523</td>\n",
       "      <td>0.468560</td>\n",
       "      <td>0.513440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513388</td>\n",
       "      <td>0.468517</td>\n",
       "      <td>0.419486</td>\n",
       "      <td>0.366732</td>\n",
       "      <td>0.310722</td>\n",
       "      <td>0.251954</td>\n",
       "      <td>0.190950</td>\n",
       "      <td>0.128249</td>\n",
       "      <td>0.064411</td>\n",
       "      <td>2.515972e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0.068632</td>\n",
       "      <td>0.136654</td>\n",
       "      <td>0.203464</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.331091</td>\n",
       "      <td>0.390774</td>\n",
       "      <td>0.446989</td>\n",
       "      <td>0.499237</td>\n",
       "      <td>0.547054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547011</td>\n",
       "      <td>0.499201</td>\n",
       "      <td>0.446959</td>\n",
       "      <td>0.390749</td>\n",
       "      <td>0.331071</td>\n",
       "      <td>0.268455</td>\n",
       "      <td>0.203454</td>\n",
       "      <td>0.136648</td>\n",
       "      <td>0.068629</td>\n",
       "      <td>2.680388e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0.073120</td>\n",
       "      <td>0.145592</td>\n",
       "      <td>0.216771</td>\n",
       "      <td>0.286026</td>\n",
       "      <td>0.352743</td>\n",
       "      <td>0.416330</td>\n",
       "      <td>0.476221</td>\n",
       "      <td>0.531885</td>\n",
       "      <td>0.582829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582794</td>\n",
       "      <td>0.531856</td>\n",
       "      <td>0.476196</td>\n",
       "      <td>0.416310</td>\n",
       "      <td>0.352728</td>\n",
       "      <td>0.286015</td>\n",
       "      <td>0.216763</td>\n",
       "      <td>0.145587</td>\n",
       "      <td>0.073118</td>\n",
       "      <td>2.855389e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.155103</td>\n",
       "      <td>0.230933</td>\n",
       "      <td>0.304713</td>\n",
       "      <td>0.375788</td>\n",
       "      <td>0.443529</td>\n",
       "      <td>0.507332</td>\n",
       "      <td>0.566633</td>\n",
       "      <td>0.620904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620878</td>\n",
       "      <td>0.566611</td>\n",
       "      <td>0.507314</td>\n",
       "      <td>0.443514</td>\n",
       "      <td>0.375777</td>\n",
       "      <td>0.304704</td>\n",
       "      <td>0.230927</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.077896</td>\n",
       "      <td>3.041667e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0.082982</td>\n",
       "      <td>0.165227</td>\n",
       "      <td>0.246007</td>\n",
       "      <td>0.324602</td>\n",
       "      <td>0.400317</td>\n",
       "      <td>0.472478</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.603617</td>\n",
       "      <td>0.661430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661413</td>\n",
       "      <td>0.603602</td>\n",
       "      <td>0.540434</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.400309</td>\n",
       "      <td>0.324596</td>\n",
       "      <td>0.246002</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>3.239956e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>0.088394</td>\n",
       "      <td>0.176003</td>\n",
       "      <td>0.262051</td>\n",
       "      <td>0.345772</td>\n",
       "      <td>0.426425</td>\n",
       "      <td>0.503292</td>\n",
       "      <td>0.575692</td>\n",
       "      <td>0.642983</td>\n",
       "      <td>0.704566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704557</td>\n",
       "      <td>0.642975</td>\n",
       "      <td>0.575686</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.426421</td>\n",
       "      <td>0.345769</td>\n",
       "      <td>0.262049</td>\n",
       "      <td>0.176002</td>\n",
       "      <td>0.088393</td>\n",
       "      <td>3.451041e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0.094155</td>\n",
       "      <td>0.187474</td>\n",
       "      <td>0.279129</td>\n",
       "      <td>0.368306</td>\n",
       "      <td>0.454215</td>\n",
       "      <td>0.536091</td>\n",
       "      <td>0.613210</td>\n",
       "      <td>0.684885</td>\n",
       "      <td>0.750481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750481</td>\n",
       "      <td>0.684885</td>\n",
       "      <td>0.613210</td>\n",
       "      <td>0.536091</td>\n",
       "      <td>0.454215</td>\n",
       "      <td>0.368306</td>\n",
       "      <td>0.279129</td>\n",
       "      <td>0.187474</td>\n",
       "      <td>0.094155</td>\n",
       "      <td>3.675754e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0         1  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0            0  0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "1            0  0.000504    0.001004    0.001496    0.001974    0.002434   \n",
       "2            0  0.001011    0.002013    0.002998    0.003955    0.004878   \n",
       "3            0  0.001522    0.003030    0.004512    0.005954    0.007343   \n",
       "4            0  0.002039    0.004060    0.006045    0.007976    0.009838   \n",
       "5            0  0.002564    0.005106    0.007602    0.010032    0.012372   \n",
       "6            0  0.003100    0.006173    0.009191    0.012128    0.014958   \n",
       "7            0  0.003648    0.007265    0.010817    0.014274    0.017605   \n",
       "8            0  0.004212    0.008387    0.012488    0.016478    0.020323   \n",
       "9            0  0.004792    0.009543    0.014209    0.018750    0.023125   \n",
       "10           0  0.005393    0.010738    0.015988    0.021097    0.026020   \n",
       "11           0  0.006015    0.011976    0.017833    0.023531    0.029021   \n",
       "12           0  0.006661    0.013264    0.019749    0.026060    0.032141   \n",
       "13           0  0.007335    0.014605    0.021746    0.028695    0.035390   \n",
       "14           0  0.008038    0.016005    0.023831    0.031446    0.038783   \n",
       "15           0  0.008774    0.017470    0.026013    0.034325    0.042333   \n",
       "16           0  0.009545    0.019006    0.028299    0.037342    0.046055   \n",
       "17           0  0.010355    0.020619    0.030700    0.040510    0.049962   \n",
       "18           0  0.011207    0.022315    0.033225    0.043842    0.054071   \n",
       "19           0  0.012103    0.024100    0.035884    0.047350    0.058397   \n",
       "20           0  0.013049    0.025983    0.038687    0.051049    0.062959   \n",
       "21           0  0.014047    0.027970    0.041646    0.054954    0.067774   \n",
       "22           0  0.015102    0.030070    0.044773    0.059079    0.072861   \n",
       "23           0  0.016217    0.032290    0.048078    0.063441    0.078241   \n",
       "24           0  0.017397    0.034640    0.051577    0.068057    0.083934   \n",
       "25           0  0.018647    0.037129    0.055282    0.072945    0.089963   \n",
       "26           0  0.019971    0.039765    0.059208    0.078126    0.096351   \n",
       "27           0  0.021375    0.042561    0.063371    0.083618    0.103125   \n",
       "28           0  0.022865    0.045527    0.067786    0.089445    0.110310   \n",
       "29           0  0.024445    0.048674    0.072472    0.095628    0.117935   \n",
       "30           0  0.026123    0.052015    0.077447    0.102192    0.126030   \n",
       "31           0  0.027905    0.055564    0.082730    0.109162    0.134627   \n",
       "32           0  0.029798    0.059333    0.088342    0.116567    0.143759   \n",
       "33           0  0.031810    0.063338    0.094305    0.124436    0.153463   \n",
       "34           0  0.033948    0.067595    0.100643    0.132798    0.163776   \n",
       "35           0  0.036220    0.072120    0.107380    0.141688    0.174739   \n",
       "36           0  0.038637    0.076931    0.114543    0.151139    0.186394   \n",
       "37           0  0.041206    0.082047    0.122160    0.161190    0.198789   \n",
       "38           0  0.043939    0.087488    0.130261    0.171879    0.211971   \n",
       "39           0  0.046845    0.093275    0.138878    0.183248    0.225993   \n",
       "40           0  0.049937    0.099432    0.148044    0.195343    0.240909   \n",
       "41           0  0.053227    0.105982    0.157796    0.208211    0.256778   \n",
       "42           0  0.056727    0.112951    0.168172    0.221901    0.273662   \n",
       "43           0  0.060451    0.120366    0.179213    0.236469    0.291627   \n",
       "44           0  0.064414    0.128257    0.190962    0.251972    0.310745   \n",
       "45           0  0.068632    0.136654    0.203464    0.268469    0.331091   \n",
       "46           0  0.073120    0.145592    0.216771    0.286026    0.352743   \n",
       "47           0  0.077897    0.155103    0.230933    0.304713    0.375788   \n",
       "48           0  0.082982    0.165227    0.246007    0.324602    0.400317   \n",
       "49           0  0.088394    0.176003    0.262051    0.345772    0.426425   \n",
       "50           0  0.094155    0.187474    0.279129    0.368306    0.454215   \n",
       "\n",
       "    Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 91  \\\n",
       "0     0.000000    0.000000    0.000000    0.000000  ...     0.000000   \n",
       "1     0.002873    0.003287    0.003671    0.004023  ...     0.004014   \n",
       "2     0.005758    0.006587    0.007358    0.008063  ...     0.008045   \n",
       "3     0.008667    0.009915    0.011075    0.012136  ...     0.012109   \n",
       "4     0.011612    0.013283    0.014837    0.016259  ...     0.016223   \n",
       "5     0.014604    0.016706    0.018660    0.020449  ...     0.020404   \n",
       "6     0.017656    0.020197    0.022559    0.024722  ...     0.024669   \n",
       "7     0.020780    0.023770    0.026551    0.029096  ...     0.029035   \n",
       "8     0.023988    0.027441    0.030651    0.033589  ...     0.033519   \n",
       "9     0.027295    0.031223    0.034876    0.038219  ...     0.038141   \n",
       "10    0.030712    0.035133    0.039242    0.043004  ...     0.042919   \n",
       "11    0.034255    0.039185    0.043768    0.047964  ...     0.047872   \n",
       "12    0.037936    0.043397    0.048472    0.053119  ...     0.053020   \n",
       "13    0.041772    0.047784    0.053373    0.058489  ...     0.058384   \n",
       "14    0.045777    0.052365    0.058490    0.064096  ...     0.063985   \n",
       "15    0.049967    0.057158    0.063843    0.069962  ...     0.069846   \n",
       "16    0.054359    0.062182    0.069455    0.076111  ...     0.075990   \n",
       "17    0.058971    0.067457    0.075347    0.082568  ...     0.082442   \n",
       "18    0.063820    0.073005    0.081542    0.089357  ...     0.089227   \n",
       "19    0.068927    0.078846    0.088067    0.096507  ...     0.096373   \n",
       "20    0.074311    0.085005    0.094945    0.104044  ...     0.103908   \n",
       "21    0.079994    0.091506    0.102206    0.112000  ...     0.111861   \n",
       "22    0.085998    0.098374    0.109877    0.120406  ...     0.120265   \n",
       "23    0.092348    0.105636    0.117988    0.129294  ...     0.129152   \n",
       "24    0.099067    0.113322    0.126572    0.138700  ...     0.138558   \n",
       "25    0.106183    0.121461    0.135663    0.148662  ...     0.148519   \n",
       "26    0.113723    0.130086    0.145296    0.159218  ...     0.159075   \n",
       "27    0.121718    0.139231    0.155510    0.170409  ...     0.170268   \n",
       "28    0.130198    0.148931    0.166344    0.182281  ...     0.182141   \n",
       "29    0.139198    0.159225    0.177841    0.194879  ...     0.194741   \n",
       "30    0.148752    0.170154    0.190047    0.208254  ...     0.208119   \n",
       "31    0.158898    0.181759    0.203009    0.222458  ...     0.222325   \n",
       "32    0.169676    0.194088    0.216778    0.237546  ...     0.237417   \n",
       "33    0.181129    0.207188    0.231409    0.253578  ...     0.253453   \n",
       "34    0.193300    0.221111    0.246959    0.270617  ...     0.270497   \n",
       "35    0.206239    0.235911    0.263489    0.288730  ...     0.288615   \n",
       "36    0.219996    0.251646    0.281064    0.307987  ...     0.307878   \n",
       "37    0.234625    0.268380    0.299753    0.328466  ...     0.328363   \n",
       "38    0.250184    0.286176    0.319629    0.350246  ...     0.350149   \n",
       "39    0.266732    0.305105    0.340770    0.373412  ...     0.373322   \n",
       "40    0.284337    0.325242    0.363261    0.398056  ...     0.397973   \n",
       "41    0.303066    0.346665    0.387188    0.424274  ...     0.424199   \n",
       "42    0.322993    0.369459    0.412645    0.452170  ...     0.452102   \n",
       "43    0.344197    0.393713    0.439734    0.481853  ...     0.481793   \n",
       "44    0.366761    0.419523    0.468560    0.513440  ...     0.513388   \n",
       "45    0.390774    0.446989    0.499237    0.547054  ...     0.547011   \n",
       "46    0.416330    0.476221    0.531885    0.582829  ...     0.582794   \n",
       "47    0.443529    0.507332    0.566633    0.620904  ...     0.620878   \n",
       "48    0.472478    0.540446    0.603617    0.661430  ...     0.661413   \n",
       "49    0.503292    0.575692    0.642983    0.704566  ...     0.704557   \n",
       "50    0.536091    0.613210    0.684885    0.750481  ...     0.750481   \n",
       "\n",
       "    Unnamed: 92  Unnamed: 93  Unnamed: 94  Unnamed: 95  Unnamed: 96  \\\n",
       "0      0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1      0.003663     0.003280     0.002868     0.002430     0.001971   \n",
       "2      0.007342     0.006574     0.005748     0.004871     0.003950   \n",
       "3      0.011052     0.009896     0.008652     0.007331     0.005945   \n",
       "4      0.014806     0.013258     0.011592     0.009822     0.007965   \n",
       "5      0.018622     0.016675     0.014579     0.012353     0.010017   \n",
       "6      0.022514     0.020160     0.017626     0.014935     0.012111   \n",
       "7      0.026499     0.023728     0.020745     0.017578     0.014254   \n",
       "8      0.030592     0.027393     0.023949     0.020293     0.016456   \n",
       "9      0.034810     0.031170     0.027251     0.023091     0.018725   \n",
       "10     0.039171     0.035074     0.030665     0.025983     0.021070   \n",
       "11     0.043691     0.039121     0.034203     0.028981     0.023501   \n",
       "12     0.048389     0.043328     0.037881     0.032098     0.026028   \n",
       "13     0.053284     0.047711     0.041713     0.035344     0.028661   \n",
       "14     0.058396     0.052288     0.045715     0.038735     0.031410   \n",
       "15     0.063745     0.057077     0.049902     0.042283     0.034287   \n",
       "16     0.069352     0.062098     0.054291     0.046002     0.037303   \n",
       "17     0.075240     0.067370     0.058900     0.049907     0.040470   \n",
       "18     0.081433     0.072914     0.063748     0.054014     0.043800   \n",
       "19     0.087954     0.078753     0.068852     0.058339     0.047307   \n",
       "20     0.094831     0.084910     0.074235     0.062900     0.051005   \n",
       "21     0.102089     0.091409     0.079917     0.067714     0.054908   \n",
       "22     0.109758     0.098276     0.085920     0.072800     0.059033   \n",
       "23     0.117868     0.105537     0.092268     0.078179     0.063394   \n",
       "24     0.126452     0.113222     0.098987     0.083871     0.068010   \n",
       "25     0.135542     0.121362     0.106102     0.089900     0.072899   \n",
       "26     0.145176     0.129987     0.113643     0.096289     0.078079   \n",
       "27     0.155390     0.139132     0.121638     0.103063     0.083572   \n",
       "28     0.166226     0.148834     0.130119     0.110249     0.089399   \n",
       "29     0.177725     0.159129     0.139120     0.117875     0.095582   \n",
       "30     0.189933     0.170059     0.148676     0.125971     0.102147   \n",
       "31     0.202897     0.181667     0.158824     0.134569     0.109119   \n",
       "32     0.216670     0.193998     0.169604     0.143703     0.116525   \n",
       "33     0.231304     0.207101     0.181059     0.153408     0.124395   \n",
       "34     0.246858     0.221027     0.193233     0.163723     0.132759   \n",
       "35     0.263392     0.235831     0.206175     0.174688     0.141650   \n",
       "36     0.280972     0.251570     0.219935     0.186346     0.151103   \n",
       "37     0.299666     0.268308     0.234567     0.198744     0.161156   \n",
       "38     0.319547     0.286108     0.250129     0.211929     0.171847   \n",
       "39     0.340694     0.305042     0.266682     0.225953     0.183219   \n",
       "40     0.363191     0.325184     0.284290     0.240872     0.195316   \n",
       "41     0.387124     0.346612     0.303023     0.256744     0.208186   \n",
       "42     0.412588     0.369411     0.322955     0.273632     0.221879   \n",
       "43     0.439684     0.393671     0.344164     0.291601     0.236450   \n",
       "44     0.468517     0.419486     0.366732     0.310722     0.251954   \n",
       "45     0.499201     0.446959     0.390749     0.331071     0.268455   \n",
       "46     0.531856     0.476196     0.416310     0.352728     0.286015   \n",
       "47     0.566611     0.507314     0.443514     0.375777     0.304704   \n",
       "48     0.603602     0.540434     0.472468     0.400309     0.324596   \n",
       "49     0.642975     0.575686     0.503287     0.426421     0.345769   \n",
       "50     0.684885     0.613210     0.536091     0.454215     0.368306   \n",
       "\n",
       "    Unnamed: 97  Unnamed: 98  Unnamed: 99  Unnamed: 100  \n",
       "0      0.000000     0.000000     0.000000  0.000000e+00  \n",
       "1      0.001494     0.001003     0.000504  2.001140e-18  \n",
       "2      0.002994     0.002011     0.001010  4.010183e-18  \n",
       "3      0.004506     0.003026     0.001520  6.035062e-18  \n",
       "4      0.006037     0.004055     0.002036  8.083775e-18  \n",
       "5      0.007592     0.005100     0.002561  1.016441e-17  \n",
       "6      0.009179     0.006165     0.003097  1.228519e-17  \n",
       "7      0.010803     0.007256     0.003645  1.445448e-17  \n",
       "8      0.012472     0.008377     0.004207  1.668086e-17  \n",
       "9      0.014192     0.009532     0.004788  1.897311e-17  \n",
       "10     0.015969     0.010726     0.005387  2.134029e-17  \n",
       "11     0.017812     0.011964     0.006009  2.379174e-17  \n",
       "12     0.019727     0.013250     0.006655  2.633715e-17  \n",
       "13     0.021722     0.014590     0.007328  2.898658e-17  \n",
       "14     0.023806     0.015990     0.008031  3.175047e-17  \n",
       "15     0.025986     0.017454     0.008766  3.463975e-17  \n",
       "16     0.028272     0.018989     0.009537  3.766583e-17  \n",
       "17     0.030672     0.020601     0.010347  4.084065e-17  \n",
       "18     0.033196     0.022297     0.011198  4.417676e-17  \n",
       "19     0.035854     0.024082     0.012095  4.768733e-17  \n",
       "20     0.038657     0.025964     0.013040  5.138622e-17  \n",
       "21     0.041615     0.027951     0.014038  5.528805e-17  \n",
       "22     0.044741     0.030050     0.015093  5.940822e-17  \n",
       "23     0.048046     0.032271     0.016208  6.376299e-17  \n",
       "24     0.051544     0.034620     0.017388  6.836958e-17  \n",
       "25     0.055249     0.037108     0.018637  7.324617e-17  \n",
       "26     0.059175     0.039745     0.019962  7.841201e-17  \n",
       "27     0.063338     0.042541     0.021366  8.388752e-17  \n",
       "28     0.067754     0.045507     0.022855  8.969431e-17  \n",
       "29     0.072441     0.048655     0.024436  9.585532e-17  \n",
       "30     0.077416     0.051996     0.026114  1.023949e-16  \n",
       "31     0.082700     0.055545     0.027897  1.093388e-16  \n",
       "32     0.088312     0.059315     0.029790  1.167145e-16  \n",
       "33     0.094276     0.063321     0.031802  1.245512e-16  \n",
       "34     0.100615     0.067578     0.033940  1.328797e-16  \n",
       "35     0.107354     0.072104     0.036213  1.417329e-16  \n",
       "36     0.114518     0.076915     0.038629  1.511459e-16  \n",
       "37     0.122136     0.082032     0.041199  1.611558e-16  \n",
       "38     0.130239     0.087474     0.043932  1.718021e-16  \n",
       "39     0.138857     0.093262     0.046839  1.831269e-16  \n",
       "40     0.148025     0.099420     0.049932  1.951749e-16  \n",
       "41     0.157779     0.105971     0.053222  2.079937e-16  \n",
       "42     0.168156     0.112941     0.056722  2.216338e-16  \n",
       "43     0.179199     0.120357     0.060447  2.361492e-16  \n",
       "44     0.190950     0.128249     0.064411  2.515972e-16  \n",
       "45     0.203454     0.136648     0.068629  2.680388e-16  \n",
       "46     0.216763     0.145587     0.073118  2.855389e-16  \n",
       "47     0.230927     0.155100     0.077896  3.041667e-16  \n",
       "48     0.246002     0.165225     0.082981  3.239956e-16  \n",
       "49     0.262049     0.176002     0.088393  3.451041e-16  \n",
       "50     0.279129     0.187474     0.094155  3.675754e-16  \n",
       "\n",
       "[51 rows x 101 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff7a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputarray=din.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea00a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 101)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef29c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "211c4089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputarray[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8da984cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_x_y(df,windowsize=5):\n",
    "    df_as_np=df.to_numpy()\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(len(df_as_np)-windowsize):\n",
    "        row=[a for a in df_as_np[i :i+5]]\n",
    "        x.append(row)\n",
    "        label=df_as_np[i+5]\n",
    "        y.append(label)\n",
    "        \n",
    "    return np.array(x),np.array(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da1a42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=df_to_x_y(din,windowsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96f33718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 5, 101)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1bf7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1bec74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=Sequential()\n",
    "Model.add(InputLayer((5,101)))\n",
    "Model.add(LSTM(256))\n",
    "\n",
    "Model.add(Dense(128,'relu'))\n",
    "Model.add(Dense(101,'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1c728d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 256)               366592    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 101)               13029     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412,517\n",
      "Trainable params: 412,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "861745bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp=ModelCheckpoint('Model',save_best_only=True)\n",
    "Model.compile(loss=MeanSquaredError(),optimizer=Adam(learning_rate=0.0001),metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42b8bf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.5589e-05 - root_mean_squared_error: 0.0051 - val_loss: 2.5824e-05 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.5962e-05 - root_mean_squared_error: 0.0051 - val_loss: 2.5927e-05 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 3/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7920e-05 - root_mean_squared_error: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.5893e-05 - root_mean_squared_error: 0.0051 - val_loss: 2.5522e-05 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 4/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0566e-05 - root_mean_squared_error: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.5523e-05 - root_mean_squared_error: 0.0051 - val_loss: 2.5391e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.6126e-05 - root_mean_squared_error: 0.0051 - val_loss: 2.5533e-05 - val_root_mean_squared_error: 0.0051\n",
      "Epoch 6/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.8218e-05 - root_mean_squared_error: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.5455e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.5132e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 7/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7388e-05 - root_mean_squared_error: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.5173e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.5114e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 8/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6459e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.5201e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4978e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 9/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0849e-05 - root_mean_squared_error: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.4921e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4822e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.4935e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4855e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 11/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7147e-05 - root_mean_squared_error: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.4950e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4615e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 12/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9310e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.4566e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4570e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 13/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9375e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.4846e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4506e-05 - val_root_mean_squared_error: 0.0050\n",
      "Epoch 14/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6411e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.4846e-05 - root_mean_squared_error: 0.0050 - val_loss: 2.4336e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 15/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5793e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.4396e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.4271e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.4243e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.4338e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 17/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7906e-05 - root_mean_squared_error: 0.0053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.4334e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.4254e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 18/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6224e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.4216e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3963e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 19/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5596e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.3943e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3817e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3785e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3821e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 21/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0864e-05 - root_mean_squared_error: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.3868e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3780e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 22/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8705e-05 - root_mean_squared_error: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.3758e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3774e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 23/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6842e-05 - root_mean_squared_error: 0.0052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.3787e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3639e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 24/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4647e-05 - root_mean_squared_error: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.3588e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3406e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.3323e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.3670e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.4079e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3617e-05 - val_root_mean_squared_error: 0.0049\n",
      "Epoch 27/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4884e-05 - root_mean_squared_error: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.3466e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.3272e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.3588e-05 - root_mean_squared_error: 0.0049 - val_loss: 2.3392e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 29/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6510e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.3360e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.3156e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 30/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4979e-05 - root_mean_squared_error: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.3207e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.3070e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 31/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6221e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.3069e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2865e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 32/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5821e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2847e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2821e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 33/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0579e-05 - root_mean_squared_error: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2788e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2758e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 34/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2789e-05 - root_mean_squared_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2760e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2664e-05 - val_root_mean_squared_error: 0.0048\n",
      "Epoch 35/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3101e-05 - root_mean_squared_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.2693e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2539e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 36/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4737e-05 - root_mean_squared_error: 0.0050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2635e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2472e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 37/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7219e-05 - root_mean_squared_error: 0.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2813e-05 - root_mean_squared_error: 0.0048 - val_loss: 2.2393e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 38/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7895e-05 - root_mean_squared_error: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.2352e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.2326e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.2268e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.2329e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 40/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8835e-05 - root_mean_squared_error: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2270e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.2311e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 41/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3205e-05 - root_mean_squared_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2490e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.2195e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 42/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3106e-05 - root_mean_squared_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2111e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.2079e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 43/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3585e-05 - root_mean_squared_error: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.2134e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.2060e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 44/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2680e-05 - root_mean_squared_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.2044e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1894e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 45/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8884e-05 - root_mean_squared_error: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.1868e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1775e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 46/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5473e-05 - root_mean_squared_error: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.1735e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1738e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.1643e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1922e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.1934e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1922e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 49/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6338e-05 - root_mean_squared_error: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.1987e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1644e-05 - val_root_mean_squared_error: 0.0047\n",
      "Epoch 50/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4210e-05 - root_mean_squared_error: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.1622e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1529e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 51/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2234e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.1474e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1411e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 52/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8764e-05 - root_mean_squared_error: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.1638e-05 - root_mean_squared_error: 0.0047 - val_loss: 2.1291e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 53/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7961e-05 - root_mean_squared_error: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.1243e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1162e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1351e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1285e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 55/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6570e-05 - root_mean_squared_error: 0.0041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.1379e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1066e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 56/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1309e-05 - root_mean_squared_error: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.1323e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.0886e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.0714e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1109e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.1262e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.1373e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1440e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.0905e-05 - val_root_mean_squared_error: 0.0046\n",
      "Epoch 60/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5894e-05 - root_mean_squared_error: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.0870e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.0669e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.0675e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0686e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.0722e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.0700e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 63/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9266e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.0758e-05 - root_mean_squared_error: 0.0046 - val_loss: 2.0478e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 64/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7649e-05 - root_mean_squared_error: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.0560e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0318e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.0378e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0325e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 66/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1852e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.0295e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0147e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.0090e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0210e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.0155e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0481e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.0614e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0233e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 70/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2544e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 2.0658e-05 - root_mean_squared_error: 0.0045 - val_loss: 2.0033e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 71/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1823e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 2.0088e-05 - root_mean_squared_error: 0.0045 - val_loss: 1.9839e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 72/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9563e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.9809e-05 - root_mean_squared_error: 0.0045 - val_loss: 1.9821e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 73/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3091e-05 - root_mean_squared_error: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.9814e-05 - root_mean_squared_error: 0.0045 - val_loss: 1.9763e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 74/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5858e-05 - root_mean_squared_error: 0.0040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 1.9988e-05 - root_mean_squared_error: 0.0045 - val_loss: 1.9562e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.9756e-05 - root_mean_squared_error: 0.0044 - val_loss: 2.0029e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2.0013e-05 - root_mean_squared_error: 0.0045 - val_loss: 1.9886e-05 - val_root_mean_squared_error: 0.0045\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 2.0196e-05 - root_mean_squared_error: 0.0045 - val_loss: 1.9578e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 78/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1765e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.9587e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9514e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 79/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0371e-05 - root_mean_squared_error: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.9525e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9341e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 80/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1884e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 1.9393e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9223e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 81/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9072e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.9196e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9181e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 82/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7892e-05 - root_mean_squared_error: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.9649e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9079e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.8913e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.9238e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.9551e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9561e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.9490e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9129e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.9641e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.9204e-05 - val_root_mean_squared_error: 0.0044\n",
      "Epoch 87/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0186e-05 - root_mean_squared_error: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 1.9189e-05 - root_mean_squared_error: 0.0044 - val_loss: 1.8869e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 88/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8036e-05 - root_mean_squared_error: 0.0042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.8869e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8785e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 89/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5193e-05 - root_mean_squared_error: 0.0039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.8779e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8671e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 90/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1216e-05 - root_mean_squared_error: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 1.8742e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8584e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 91/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9580e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.8570e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8557e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 92/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2313e-05 - root_mean_squared_error: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 1.8575e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8513e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 93/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9923e-05 - root_mean_squared_error: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.8537e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8441e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 94/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4017e-05 - root_mean_squared_error: 0.0037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 7s/step - loss: 1.8565e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8281e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.8863e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8631e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 96/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9555e-05 - root_mean_squared_error: 0.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 8s/step - loss: 1.8621e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8226e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.8057e-05 - root_mean_squared_error: 0.0042 - val_loss: 1.8405e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.8333e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8767e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.8726e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8442e-05 - val_root_mean_squared_error: 0.0043\n",
      "Epoch 100/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1169e-05 - root_mean_squared_error: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/2 [==============================] - 8s 8s/step - loss: 1.8532e-05 - root_mean_squared_error: 0.0043 - val_loss: 1.8123e-05 - val_root_mean_squared_error: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264e5fb1340>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(x,y,validation_data=(x,y),epochs=100,callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4b26d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8fc0ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=load_model('Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f67f082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions = model1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25cef667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 101)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2146945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 101)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8cf94a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "252cd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "error=y-train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1ad4d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error=pd.DataFrame(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93c9c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 256)               366592    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 101)               13029     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412,517\n",
      "Trainable params: 412,517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5f6b98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "69f3df24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001806</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.022304</td>\n",
       "      <td>0.022561</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026076</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.013043</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>-0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001611</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.024665</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.028471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029914</td>\n",
       "      <td>0.028008</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>0.019193</td>\n",
       "      <td>0.013694</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>-0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001419</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.020247</td>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.028927</td>\n",
       "      <td>0.032731</td>\n",
       "      <td>0.032459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.031761</td>\n",
       "      <td>0.031117</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.015404</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>-0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001229</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>0.029591</td>\n",
       "      <td>0.032231</td>\n",
       "      <td>0.036402</td>\n",
       "      <td>0.036554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037865</td>\n",
       "      <td>0.035607</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>0.018745</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>-0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.035635</td>\n",
       "      <td>0.040186</td>\n",
       "      <td>0.040774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042014</td>\n",
       "      <td>0.039564</td>\n",
       "      <td>0.037914</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>0.020748</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>-0.001517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000854</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.025789</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>0.034871</td>\n",
       "      <td>0.039154</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>0.045138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046303</td>\n",
       "      <td>0.043649</td>\n",
       "      <td>0.041461</td>\n",
       "      <td>0.031539</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.022817</td>\n",
       "      <td>0.020498</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>-0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000668</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.037676</td>\n",
       "      <td>0.042805</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>0.047880</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.034870</td>\n",
       "      <td>0.026275</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.022295</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>-0.001859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000482</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>0.021338</td>\n",
       "      <td>0.029874</td>\n",
       "      <td>0.033078</td>\n",
       "      <td>0.040611</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>0.052390</td>\n",
       "      <td>0.054382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055386</td>\n",
       "      <td>0.052277</td>\n",
       "      <td>0.048930</td>\n",
       "      <td>0.038327</td>\n",
       "      <td>0.029096</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>-0.002025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.032042</td>\n",
       "      <td>0.035972</td>\n",
       "      <td>0.043717</td>\n",
       "      <td>0.050557</td>\n",
       "      <td>0.056796</td>\n",
       "      <td>0.059271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.056831</td>\n",
       "      <td>0.052912</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>0.032030</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.026083</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>-0.002169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.007987</td>\n",
       "      <td>0.015147</td>\n",
       "      <td>0.024969</td>\n",
       "      <td>0.034312</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>0.046995</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>0.061407</td>\n",
       "      <td>0.064377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065207</td>\n",
       "      <td>0.061578</td>\n",
       "      <td>0.057078</td>\n",
       "      <td>0.045645</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>-0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.026920</td>\n",
       "      <td>0.036695</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.050457</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.066251</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070477</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.061438</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.034582</td>\n",
       "      <td>0.030179</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>-0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>0.028975</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.045555</td>\n",
       "      <td>0.054122</td>\n",
       "      <td>0.063587</td>\n",
       "      <td>0.071351</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076025</td>\n",
       "      <td>0.071780</td>\n",
       "      <td>0.066013</td>\n",
       "      <td>0.053662</td>\n",
       "      <td>0.041751</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.032367</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>-0.002545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.041856</td>\n",
       "      <td>0.049101</td>\n",
       "      <td>0.058012</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.076733</td>\n",
       "      <td>0.081326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081882</td>\n",
       "      <td>0.077282</td>\n",
       "      <td>0.070826</td>\n",
       "      <td>0.057983</td>\n",
       "      <td>0.045362</td>\n",
       "      <td>0.040165</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>-0.002657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.033447</td>\n",
       "      <td>0.044663</td>\n",
       "      <td>0.052853</td>\n",
       "      <td>0.062150</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>0.082427</td>\n",
       "      <td>0.087613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088077</td>\n",
       "      <td>0.083086</td>\n",
       "      <td>0.075901</td>\n",
       "      <td>0.062540</td>\n",
       "      <td>0.049189</td>\n",
       "      <td>0.043193</td>\n",
       "      <td>0.037067</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>-0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.013071</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>0.056829</td>\n",
       "      <td>0.066561</td>\n",
       "      <td>0.078873</td>\n",
       "      <td>0.088460</td>\n",
       "      <td>0.094271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094644</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.081261</td>\n",
       "      <td>0.067356</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>0.012688</td>\n",
       "      <td>-0.002854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.025519</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>0.050808</td>\n",
       "      <td>0.061053</td>\n",
       "      <td>0.071273</td>\n",
       "      <td>0.084588</td>\n",
       "      <td>0.094864</td>\n",
       "      <td>0.101332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101617</td>\n",
       "      <td>0.095716</td>\n",
       "      <td>0.086935</td>\n",
       "      <td>0.072454</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>0.049803</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>-0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>0.027590</td>\n",
       "      <td>0.041241</td>\n",
       "      <td>0.054183</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>0.076314</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.101673</td>\n",
       "      <td>0.108834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109035</td>\n",
       "      <td>0.102603</td>\n",
       "      <td>0.092951</td>\n",
       "      <td>0.077860</td>\n",
       "      <td>0.062184</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.045086</td>\n",
       "      <td>0.027313</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>-0.003006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.016631</td>\n",
       "      <td>0.029781</td>\n",
       "      <td>0.044185</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>0.070332</td>\n",
       "      <td>0.081716</td>\n",
       "      <td>0.097121</td>\n",
       "      <td>0.108922</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116938</td>\n",
       "      <td>0.109915</td>\n",
       "      <td>0.099340</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>0.067098</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.048062</td>\n",
       "      <td>0.029456</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>-0.003061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.047328</td>\n",
       "      <td>0.061639</td>\n",
       "      <td>0.075437</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>0.104004</td>\n",
       "      <td>0.116648</td>\n",
       "      <td>0.125315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125368</td>\n",
       "      <td>0.117689</td>\n",
       "      <td>0.106134</td>\n",
       "      <td>0.089708</td>\n",
       "      <td>0.072346</td>\n",
       "      <td>0.061374</td>\n",
       "      <td>0.051210</td>\n",
       "      <td>0.031716</td>\n",
       "      <td>0.016521</td>\n",
       "      <td>-0.003099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.034557</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>0.065766</td>\n",
       "      <td>0.080888</td>\n",
       "      <td>0.093742</td>\n",
       "      <td>0.111344</td>\n",
       "      <td>0.124891</td>\n",
       "      <td>0.134378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134371</td>\n",
       "      <td>0.125962</td>\n",
       "      <td>0.113370</td>\n",
       "      <td>0.096210</td>\n",
       "      <td>0.077957</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>0.054544</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.017604</td>\n",
       "      <td>-0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>0.037161</td>\n",
       "      <td>0.054279</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>0.086715</td>\n",
       "      <td>0.100441</td>\n",
       "      <td>0.119180</td>\n",
       "      <td>0.133694</td>\n",
       "      <td>0.144050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143996</td>\n",
       "      <td>0.134774</td>\n",
       "      <td>0.121085</td>\n",
       "      <td>0.103140</td>\n",
       "      <td>0.083959</td>\n",
       "      <td>0.070437</td>\n",
       "      <td>0.058077</td>\n",
       "      <td>0.036623</td>\n",
       "      <td>0.018745</td>\n",
       "      <td>-0.003117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.039922</td>\n",
       "      <td>0.058126</td>\n",
       "      <td>0.074947</td>\n",
       "      <td>0.092948</td>\n",
       "      <td>0.107651</td>\n",
       "      <td>0.127551</td>\n",
       "      <td>0.143099</td>\n",
       "      <td>0.154381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154294</td>\n",
       "      <td>0.144166</td>\n",
       "      <td>0.129318</td>\n",
       "      <td>0.110535</td>\n",
       "      <td>0.090384</td>\n",
       "      <td>0.075445</td>\n",
       "      <td>0.061824</td>\n",
       "      <td>0.039288</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>-0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.023651</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.062246</td>\n",
       "      <td>0.080060</td>\n",
       "      <td>0.099619</td>\n",
       "      <td>0.115418</td>\n",
       "      <td>0.136499</td>\n",
       "      <td>0.153153</td>\n",
       "      <td>0.165422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165320</td>\n",
       "      <td>0.154185</td>\n",
       "      <td>0.138115</td>\n",
       "      <td>0.118430</td>\n",
       "      <td>0.097264</td>\n",
       "      <td>0.080807</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.042108</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>-0.003043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.045957</td>\n",
       "      <td>0.066661</td>\n",
       "      <td>0.085562</td>\n",
       "      <td>0.106763</td>\n",
       "      <td>0.123787</td>\n",
       "      <td>0.146069</td>\n",
       "      <td>0.163905</td>\n",
       "      <td>0.177226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177130</td>\n",
       "      <td>0.164875</td>\n",
       "      <td>0.147519</td>\n",
       "      <td>0.126867</td>\n",
       "      <td>0.104634</td>\n",
       "      <td>0.086551</td>\n",
       "      <td>0.070023</td>\n",
       "      <td>0.045093</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>-0.002966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.026896</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>0.071393</td>\n",
       "      <td>0.091489</td>\n",
       "      <td>0.114415</td>\n",
       "      <td>0.132806</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.175403</td>\n",
       "      <td>0.189852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189784</td>\n",
       "      <td>0.176287</td>\n",
       "      <td>0.157581</td>\n",
       "      <td>0.135886</td>\n",
       "      <td>0.112527</td>\n",
       "      <td>0.092707</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.048253</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>-0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>0.076465</td>\n",
       "      <td>0.097877</td>\n",
       "      <td>0.122612</td>\n",
       "      <td>0.142525</td>\n",
       "      <td>0.167263</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203344</td>\n",
       "      <td>0.188472</td>\n",
       "      <td>0.168351</td>\n",
       "      <td>0.145531</td>\n",
       "      <td>0.120981</td>\n",
       "      <td>0.099308</td>\n",
       "      <td>0.079279</td>\n",
       "      <td>0.051602</td>\n",
       "      <td>0.025532</td>\n",
       "      <td>-0.002722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.030416</td>\n",
       "      <td>0.056443</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.104764</td>\n",
       "      <td>0.131391</td>\n",
       "      <td>0.152996</td>\n",
       "      <td>0.178985</td>\n",
       "      <td>0.200848</td>\n",
       "      <td>0.217806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217873</td>\n",
       "      <td>0.201482</td>\n",
       "      <td>0.179885</td>\n",
       "      <td>0.155849</td>\n",
       "      <td>0.130030</td>\n",
       "      <td>0.106387</td>\n",
       "      <td>0.084351</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>-0.002553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>0.060362</td>\n",
       "      <td>0.087720</td>\n",
       "      <td>0.112188</td>\n",
       "      <td>0.140792</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.191526</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.233259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233436</td>\n",
       "      <td>0.215374</td>\n",
       "      <td>0.192239</td>\n",
       "      <td>0.166885</td>\n",
       "      <td>0.139711</td>\n",
       "      <td>0.113976</td>\n",
       "      <td>0.089746</td>\n",
       "      <td>0.058917</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>-0.002351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.034227</td>\n",
       "      <td>0.064511</td>\n",
       "      <td>0.093949</td>\n",
       "      <td>0.120192</td>\n",
       "      <td>0.150853</td>\n",
       "      <td>0.176398</td>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.229910</td>\n",
       "      <td>0.249782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250097</td>\n",
       "      <td>0.230203</td>\n",
       "      <td>0.205473</td>\n",
       "      <td>0.178689</td>\n",
       "      <td>0.150059</td>\n",
       "      <td>0.122109</td>\n",
       "      <td>0.095488</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>0.030744</td>\n",
       "      <td>-0.002117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>0.068899</td>\n",
       "      <td>0.100608</td>\n",
       "      <td>0.128813</td>\n",
       "      <td>0.161613</td>\n",
       "      <td>0.189429</td>\n",
       "      <td>0.219276</td>\n",
       "      <td>0.245930</td>\n",
       "      <td>0.267440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267920</td>\n",
       "      <td>0.246028</td>\n",
       "      <td>0.219646</td>\n",
       "      <td>0.191311</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.130822</td>\n",
       "      <td>0.101602</td>\n",
       "      <td>0.067154</td>\n",
       "      <td>0.032734</td>\n",
       "      <td>-0.001850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.073537</td>\n",
       "      <td>0.107718</td>\n",
       "      <td>0.138091</td>\n",
       "      <td>0.173110</td>\n",
       "      <td>0.203408</td>\n",
       "      <td>0.234590</td>\n",
       "      <td>0.263011</td>\n",
       "      <td>0.286298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286966</td>\n",
       "      <td>0.262909</td>\n",
       "      <td>0.234821</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.172890</td>\n",
       "      <td>0.140145</td>\n",
       "      <td>0.108115</td>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.034874</td>\n",
       "      <td>-0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.040528</td>\n",
       "      <td>0.078433</td>\n",
       "      <td>0.115297</td>\n",
       "      <td>0.148059</td>\n",
       "      <td>0.185379</td>\n",
       "      <td>0.218375</td>\n",
       "      <td>0.250931</td>\n",
       "      <td>0.281203</td>\n",
       "      <td>0.306419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307294</td>\n",
       "      <td>0.280905</td>\n",
       "      <td>0.251058</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.185433</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.115058</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>-0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.042798</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.123360</td>\n",
       "      <td>0.158750</td>\n",
       "      <td>0.198454</td>\n",
       "      <td>0.234364</td>\n",
       "      <td>0.268346</td>\n",
       "      <td>0.300550</td>\n",
       "      <td>0.327865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328956</td>\n",
       "      <td>0.300076</td>\n",
       "      <td>0.268416</td>\n",
       "      <td>0.234564</td>\n",
       "      <td>0.198763</td>\n",
       "      <td>0.160741</td>\n",
       "      <td>0.122464</td>\n",
       "      <td>0.081560</td>\n",
       "      <td>0.039671</td>\n",
       "      <td>-0.000875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.089046</td>\n",
       "      <td>0.131917</td>\n",
       "      <td>0.170186</td>\n",
       "      <td>0.212365</td>\n",
       "      <td>0.251396</td>\n",
       "      <td>0.286880</td>\n",
       "      <td>0.321095</td>\n",
       "      <td>0.350695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351997</td>\n",
       "      <td>0.320480</td>\n",
       "      <td>0.286952</td>\n",
       "      <td>0.250931</td>\n",
       "      <td>0.212898</td>\n",
       "      <td>0.172062</td>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.086999</td>\n",
       "      <td>0.042366</td>\n",
       "      <td>-0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.000496</td>\n",
       "      <td>0.047629</td>\n",
       "      <td>0.094785</td>\n",
       "      <td>0.140972</td>\n",
       "      <td>0.182380</td>\n",
       "      <td>0.227135</td>\n",
       "      <td>0.269484</td>\n",
       "      <td>0.306566</td>\n",
       "      <td>0.342870</td>\n",
       "      <td>0.374959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376453</td>\n",
       "      <td>0.342172</td>\n",
       "      <td>0.306716</td>\n",
       "      <td>0.268340</td>\n",
       "      <td>0.227853</td>\n",
       "      <td>0.184090</td>\n",
       "      <td>0.138818</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.045284</td>\n",
       "      <td>-0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>0.150524</td>\n",
       "      <td>0.195334</td>\n",
       "      <td>0.242781</td>\n",
       "      <td>0.288621</td>\n",
       "      <td>0.327435</td>\n",
       "      <td>0.365903</td>\n",
       "      <td>0.400705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402348</td>\n",
       "      <td>0.365207</td>\n",
       "      <td>0.327750</td>\n",
       "      <td>0.286823</td>\n",
       "      <td>0.243630</td>\n",
       "      <td>0.196830</td>\n",
       "      <td>0.147854</td>\n",
       "      <td>0.099005</td>\n",
       "      <td>0.048447</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.001198</td>\n",
       "      <td>0.052926</td>\n",
       "      <td>0.107189</td>\n",
       "      <td>0.160559</td>\n",
       "      <td>0.209034</td>\n",
       "      <td>0.259313</td>\n",
       "      <td>0.308785</td>\n",
       "      <td>0.349502</td>\n",
       "      <td>0.390211</td>\n",
       "      <td>0.427967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429693</td>\n",
       "      <td>0.389630</td>\n",
       "      <td>0.350085</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.260226</td>\n",
       "      <td>0.210283</td>\n",
       "      <td>0.157528</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.000650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.001548</td>\n",
       "      <td>0.055797</td>\n",
       "      <td>0.113883</td>\n",
       "      <td>0.171054</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>0.276726</td>\n",
       "      <td>0.329933</td>\n",
       "      <td>0.372772</td>\n",
       "      <td>0.415798</td>\n",
       "      <td>0.456769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458483</td>\n",
       "      <td>0.415480</td>\n",
       "      <td>0.373738</td>\n",
       "      <td>0.327083</td>\n",
       "      <td>0.277622</td>\n",
       "      <td>0.224432</td>\n",
       "      <td>0.167897</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.055589</td>\n",
       "      <td>0.001016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>0.120929</td>\n",
       "      <td>0.181973</td>\n",
       "      <td>0.238527</td>\n",
       "      <td>0.295006</td>\n",
       "      <td>0.351994</td>\n",
       "      <td>0.397232</td>\n",
       "      <td>0.442653</td>\n",
       "      <td>0.487121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488695</td>\n",
       "      <td>0.442779</td>\n",
       "      <td>0.398707</td>\n",
       "      <td>0.348866</td>\n",
       "      <td>0.295787</td>\n",
       "      <td>0.239253</td>\n",
       "      <td>0.179021</td>\n",
       "      <td>0.120379</td>\n",
       "      <td>0.059601</td>\n",
       "      <td>0.001349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.002121</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>0.128513</td>\n",
       "      <td>0.193417</td>\n",
       "      <td>0.253945</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.374788</td>\n",
       "      <td>0.422738</td>\n",
       "      <td>0.470987</td>\n",
       "      <td>0.518975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520485</td>\n",
       "      <td>0.471801</td>\n",
       "      <td>0.424914</td>\n",
       "      <td>0.371764</td>\n",
       "      <td>0.314950</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>0.190743</td>\n",
       "      <td>0.128882</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.001516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.002013</td>\n",
       "      <td>0.066278</td>\n",
       "      <td>0.135891</td>\n",
       "      <td>0.205018</td>\n",
       "      <td>0.269966</td>\n",
       "      <td>0.334394</td>\n",
       "      <td>0.397981</td>\n",
       "      <td>0.449606</td>\n",
       "      <td>0.501122</td>\n",
       "      <td>0.553099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553638</td>\n",
       "      <td>0.501793</td>\n",
       "      <td>0.452102</td>\n",
       "      <td>0.395224</td>\n",
       "      <td>0.335257</td>\n",
       "      <td>0.272007</td>\n",
       "      <td>0.203454</td>\n",
       "      <td>0.137469</td>\n",
       "      <td>0.069829</td>\n",
       "      <td>0.001522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.144389</td>\n",
       "      <td>0.217209</td>\n",
       "      <td>0.287028</td>\n",
       "      <td>0.355875</td>\n",
       "      <td>0.421834</td>\n",
       "      <td>0.478655</td>\n",
       "      <td>0.533310</td>\n",
       "      <td>0.588396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587952</td>\n",
       "      <td>0.533661</td>\n",
       "      <td>0.479596</td>\n",
       "      <td>0.419543</td>\n",
       "      <td>0.356845</td>\n",
       "      <td>0.289218</td>\n",
       "      <td>0.216321</td>\n",
       "      <td>0.146316</td>\n",
       "      <td>0.075394</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.078596</td>\n",
       "      <td>0.154050</td>\n",
       "      <td>0.229866</td>\n",
       "      <td>0.304794</td>\n",
       "      <td>0.378472</td>\n",
       "      <td>0.446193</td>\n",
       "      <td>0.509456</td>\n",
       "      <td>0.567118</td>\n",
       "      <td>0.624632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623343</td>\n",
       "      <td>0.567396</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>0.444787</td>\n",
       "      <td>0.379348</td>\n",
       "      <td>0.306534</td>\n",
       "      <td>0.229513</td>\n",
       "      <td>0.155739</td>\n",
       "      <td>0.080870</td>\n",
       "      <td>-0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.085927</td>\n",
       "      <td>0.164208</td>\n",
       "      <td>0.242604</td>\n",
       "      <td>0.322803</td>\n",
       "      <td>0.401730</td>\n",
       "      <td>0.470562</td>\n",
       "      <td>0.541155</td>\n",
       "      <td>0.602018</td>\n",
       "      <td>0.662198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659640</td>\n",
       "      <td>0.602453</td>\n",
       "      <td>0.536207</td>\n",
       "      <td>0.470861</td>\n",
       "      <td>0.402199</td>\n",
       "      <td>0.324334</td>\n",
       "      <td>0.243602</td>\n",
       "      <td>0.165839</td>\n",
       "      <td>0.086714</td>\n",
       "      <td>-0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.255291</td>\n",
       "      <td>0.340906</td>\n",
       "      <td>0.425495</td>\n",
       "      <td>0.494660</td>\n",
       "      <td>0.573563</td>\n",
       "      <td>0.637823</td>\n",
       "      <td>0.700962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696653</td>\n",
       "      <td>0.638675</td>\n",
       "      <td>0.565433</td>\n",
       "      <td>0.497652</td>\n",
       "      <td>0.425178</td>\n",
       "      <td>0.342535</td>\n",
       "      <td>0.258629</td>\n",
       "      <td>0.176647</td>\n",
       "      <td>0.092895</td>\n",
       "      <td>-0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.102594</td>\n",
       "      <td>0.185943</td>\n",
       "      <td>0.267732</td>\n",
       "      <td>0.358867</td>\n",
       "      <td>0.449499</td>\n",
       "      <td>0.518287</td>\n",
       "      <td>0.606572</td>\n",
       "      <td>0.674317</td>\n",
       "      <td>0.740681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734274</td>\n",
       "      <td>0.675792</td>\n",
       "      <td>0.595081</td>\n",
       "      <td>0.524873</td>\n",
       "      <td>0.448186</td>\n",
       "      <td>0.360920</td>\n",
       "      <td>0.274655</td>\n",
       "      <td>0.188158</td>\n",
       "      <td>0.099288</td>\n",
       "      <td>-0.005547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0  -0.001806  0.000226  0.003744  0.010526  0.016668  0.015630  0.022304   \n",
       "1  -0.001611  0.001036  0.004872  0.011936  0.018403  0.017913  0.024665   \n",
       "2  -0.001419  0.001854  0.006023  0.013380  0.020174  0.020247  0.027090   \n",
       "3  -0.001229  0.002683  0.007202  0.014864  0.021990  0.022644  0.029591   \n",
       "4  -0.001041  0.003527  0.008414  0.016394  0.023859  0.025114  0.032181   \n",
       "5  -0.000854  0.004387  0.009663  0.017978  0.025789  0.027668  0.034871   \n",
       "6  -0.000668  0.005268  0.010956  0.019623  0.027791  0.030318  0.037676   \n",
       "7  -0.000482  0.006173  0.012297  0.021338  0.029874  0.033078  0.040611   \n",
       "8  -0.000319  0.007072  0.013692  0.023114  0.032042  0.035972  0.043717   \n",
       "9  -0.000166  0.007987  0.015147  0.024969  0.034312  0.039008  0.046995   \n",
       "10 -0.000015  0.008932  0.016669  0.026920  0.036695  0.042197  0.050457   \n",
       "11  0.000132  0.009910  0.018264  0.028975  0.039205  0.045555  0.054122   \n",
       "12  0.000277  0.010924  0.019939  0.031148  0.041856  0.049101  0.058012   \n",
       "13  0.000418  0.011977  0.021701  0.033447  0.044663  0.052853  0.062150   \n",
       "14  0.000553  0.013071  0.023559  0.035887  0.047641  0.056829  0.066561   \n",
       "15  0.000683  0.014210  0.025519  0.038481  0.050808  0.061053  0.071273   \n",
       "16  0.000806  0.015395  0.027590  0.041241  0.054183  0.065546  0.076314   \n",
       "17  0.000921  0.016631  0.029781  0.044185  0.057786  0.070332  0.081716   \n",
       "18  0.001025  0.017920  0.032100  0.047328  0.061639  0.075437  0.087513   \n",
       "19  0.001118  0.019263  0.034557  0.050686  0.065766  0.080888  0.093742   \n",
       "20  0.001196  0.020665  0.037161  0.054279  0.070193  0.086715  0.100441   \n",
       "21  0.001258  0.022127  0.039922  0.058126  0.074947  0.092948  0.107651   \n",
       "22  0.001300  0.023651  0.042851  0.062246  0.080060  0.099619  0.115418   \n",
       "23  0.001321  0.025240  0.045957  0.066661  0.085562  0.106763  0.123787   \n",
       "24  0.001318  0.026896  0.049250  0.071393  0.091489  0.114415  0.132806   \n",
       "25  0.001287  0.028621  0.052742  0.076465  0.097877  0.122612  0.142525   \n",
       "26  0.001226  0.030416  0.056443  0.081900  0.104764  0.131391  0.152996   \n",
       "27  0.001133  0.032284  0.060362  0.087720  0.112188  0.140792  0.164270   \n",
       "28  0.001005  0.034227  0.064511  0.093949  0.120192  0.150853  0.176398   \n",
       "29  0.000841  0.036246  0.068899  0.100608  0.128813  0.161613  0.189429   \n",
       "30  0.000641  0.038346  0.073537  0.107718  0.138091  0.173110  0.203408   \n",
       "31  0.000405  0.040528  0.078433  0.115297  0.148059  0.185379  0.218375   \n",
       "32  0.000134  0.042798  0.083600  0.123360  0.158750  0.198454  0.234364   \n",
       "33 -0.000168  0.045161  0.089046  0.131917  0.170186  0.212365  0.251396   \n",
       "34 -0.000496  0.047629  0.094785  0.140972  0.182380  0.227135  0.269484   \n",
       "35 -0.000843  0.050211  0.100828  0.150524  0.195334  0.242781  0.288621   \n",
       "36 -0.001198  0.052926  0.107189  0.160559  0.209034  0.259313  0.308785   \n",
       "37 -0.001548  0.055797  0.113883  0.171054  0.223448  0.276726  0.329933   \n",
       "38 -0.001875  0.058853  0.120929  0.181973  0.238527  0.295006  0.351994   \n",
       "39 -0.002121  0.062158  0.128513  0.193417  0.253945  0.314270  0.374788   \n",
       "40 -0.002013  0.066278  0.135891  0.205018  0.269966  0.334394  0.397981   \n",
       "41 -0.001035  0.071865  0.144389  0.217209  0.287028  0.355875  0.421834   \n",
       "42  0.000608  0.078596  0.154050  0.229866  0.304794  0.378472  0.446193   \n",
       "43  0.002601  0.085927  0.164208  0.242604  0.322803  0.401730  0.470562   \n",
       "44  0.004978  0.093889  0.174849  0.255291  0.340906  0.425495  0.494660   \n",
       "45  0.007722  0.102594  0.185943  0.267732  0.358867  0.449499  0.518287   \n",
       "\n",
       "         7         8         9    ...       91        92        93        94   \\\n",
       "0   0.022561  0.025660  0.024573  ...  0.026076  0.024333  0.024615  0.016283   \n",
       "1   0.025708  0.029156  0.028471  ...  0.029914  0.028008  0.027836  0.019193   \n",
       "2   0.028927  0.032731  0.032459  ...  0.033838  0.031761  0.031117  0.022161   \n",
       "3   0.032231  0.036402  0.036554  ...  0.037865  0.035607  0.034471  0.025199   \n",
       "4   0.035635  0.040186  0.040774  ...  0.042014  0.039564  0.037914  0.028320   \n",
       "5   0.039154  0.044099  0.045138  ...  0.046303  0.043649  0.041461  0.031539   \n",
       "6   0.042805  0.048161  0.049667  ...  0.050753  0.047880  0.045128  0.034870   \n",
       "7   0.046605  0.052390  0.054382  ...  0.055386  0.052277  0.048930  0.038327   \n",
       "8   0.050557  0.056796  0.059271  ...  0.060189  0.056831  0.052912  0.041910   \n",
       "9   0.054687  0.061407  0.064377  ...  0.065207  0.061578  0.057078  0.045645   \n",
       "10  0.059024  0.066251  0.069737  ...  0.070477  0.066554  0.061438  0.049556   \n",
       "11  0.063587  0.071351  0.075377  ...  0.076025  0.071780  0.066013  0.053662   \n",
       "12  0.068399  0.076733  0.081326  ...  0.081882  0.077282  0.070826  0.057983   \n",
       "13  0.073486  0.082427  0.087613  ...  0.088077  0.083086  0.075901  0.062540   \n",
       "14  0.078873  0.088460  0.094271  ...  0.094644  0.089221  0.081261  0.067356   \n",
       "15  0.084588  0.094864  0.101332  ...  0.101617  0.095716  0.086935  0.072454   \n",
       "16  0.090660  0.101673  0.108834  ...  0.109035  0.102603  0.092951  0.077860   \n",
       "17  0.097121  0.108922  0.116814  ...  0.116938  0.109915  0.099340  0.083601   \n",
       "18  0.104004  0.116648  0.125315  ...  0.125368  0.117689  0.106134  0.089708   \n",
       "19  0.111344  0.124891  0.134378  ...  0.134371  0.125962  0.113370  0.096210   \n",
       "20  0.119180  0.133694  0.144050  ...  0.143996  0.134774  0.121085  0.103140   \n",
       "21  0.127551  0.143099  0.154381  ...  0.154294  0.144166  0.129318  0.110535   \n",
       "22  0.136499  0.153153  0.165422  ...  0.165320  0.154185  0.138115  0.118430   \n",
       "23  0.146069  0.163905  0.177226  ...  0.177130  0.164875  0.147519  0.126867   \n",
       "24  0.156307  0.175403  0.189852  ...  0.189784  0.176287  0.157581  0.135886   \n",
       "25  0.167263  0.187700  0.203358  ...  0.203344  0.188472  0.168351  0.145531   \n",
       "26  0.178985  0.200848  0.217806  ...  0.217873  0.201482  0.179885  0.155849   \n",
       "27  0.191526  0.214900  0.233259  ...  0.233436  0.215374  0.192239  0.166885   \n",
       "28  0.204939  0.229910  0.249782  ...  0.250097  0.230203  0.205473  0.178689   \n",
       "29  0.219276  0.245930  0.267440  ...  0.267920  0.246028  0.219646  0.191311   \n",
       "30  0.234590  0.263011  0.286298  ...  0.286966  0.262909  0.234821  0.204798   \n",
       "31  0.250931  0.281203  0.306419  ...  0.307294  0.280905  0.251058  0.219200   \n",
       "32  0.268346  0.300550  0.327865  ...  0.328956  0.300076  0.268416  0.234564   \n",
       "33  0.286880  0.321095  0.350695  ...  0.351997  0.320480  0.286952  0.250931   \n",
       "34  0.306566  0.342870  0.374959  ...  0.376453  0.342172  0.306716  0.268340   \n",
       "35  0.327435  0.365903  0.400705  ...  0.402348  0.365207  0.327750  0.286823   \n",
       "36  0.349502  0.390211  0.427967  ...  0.429693  0.389630  0.350085  0.306400   \n",
       "37  0.372772  0.415798  0.456769  ...  0.458483  0.415480  0.373738  0.327083   \n",
       "38  0.397232  0.442653  0.487121  ...  0.488695  0.442779  0.398707  0.348866   \n",
       "39  0.422738  0.470987  0.518975  ...  0.520485  0.471801  0.424914  0.371764   \n",
       "40  0.449606  0.501122  0.553099  ...  0.553638  0.501793  0.452102  0.395224   \n",
       "41  0.478655  0.533310  0.588396  ...  0.587952  0.533661  0.479596  0.419543   \n",
       "42  0.509456  0.567118  0.624632  ...  0.623343  0.567396  0.507538  0.444787   \n",
       "43  0.541155  0.602018  0.662198  ...  0.659640  0.602453  0.536207  0.470861   \n",
       "44  0.573563  0.637823  0.700962  ...  0.696653  0.638675  0.565433  0.497652   \n",
       "45  0.606572  0.674317  0.740681  ...  0.734274  0.675792  0.595081  0.524873   \n",
       "\n",
       "         95        96        97        98        99        100  \n",
       "0   0.011399  0.013043  0.012187  0.002981  0.002742 -0.000797  \n",
       "1   0.013694  0.014901  0.013782  0.004192  0.003369 -0.000983  \n",
       "2   0.016047  0.016799  0.015404  0.005424  0.004002 -0.001164  \n",
       "3   0.018471  0.018745  0.017059  0.006680  0.004645 -0.001342  \n",
       "4   0.020975  0.020748  0.018755  0.007968  0.005300 -0.001517  \n",
       "5   0.023572  0.022817  0.020498  0.009290  0.005969 -0.001689  \n",
       "6   0.026275  0.024962  0.022295  0.010655  0.006656 -0.001859  \n",
       "7   0.029096  0.027193  0.024156  0.012065  0.007363 -0.002025  \n",
       "8   0.032030  0.029539  0.026083  0.013492  0.008055 -0.002169  \n",
       "9   0.035103  0.032000  0.028088  0.014961  0.008757 -0.002300  \n",
       "10  0.038337  0.034582  0.030179  0.016491  0.009483 -0.002426  \n",
       "11  0.041751  0.037300  0.032367  0.018088  0.010236 -0.002545  \n",
       "12  0.045362  0.040165  0.034660  0.019759  0.011019 -0.002657  \n",
       "13  0.049189  0.043193  0.037067  0.021510  0.011836 -0.002761  \n",
       "14  0.053254  0.046400  0.039600  0.023348  0.012688 -0.002854  \n",
       "15  0.057578  0.049803  0.042269  0.025280  0.013579 -0.002937  \n",
       "16  0.062184  0.053419  0.045086  0.027313  0.014512 -0.003006  \n",
       "17  0.067098  0.057270  0.048062  0.029456  0.015492 -0.003061  \n",
       "18  0.072346  0.061374  0.051210  0.031716  0.016521 -0.003099  \n",
       "19  0.077957  0.065755  0.054544  0.034102  0.017604 -0.003118  \n",
       "20  0.083959  0.070437  0.058077  0.036623  0.018745 -0.003117  \n",
       "21  0.090384  0.075445  0.061824  0.039288  0.019951 -0.003092  \n",
       "22  0.097264  0.080807  0.065800  0.042108  0.021225 -0.003043  \n",
       "23  0.104634  0.086551  0.070023  0.045093  0.022575 -0.002966  \n",
       "24  0.112527  0.092707  0.074510  0.048253  0.024008 -0.002859  \n",
       "25  0.120981  0.099308  0.079279  0.051602  0.025532 -0.002722  \n",
       "26  0.130030  0.106387  0.084351  0.055152  0.027155 -0.002553  \n",
       "27  0.139711  0.113976  0.089746  0.058917  0.028889 -0.002351  \n",
       "28  0.150059  0.122109  0.095488  0.062912  0.030744 -0.002117  \n",
       "29  0.161108  0.130822  0.101602  0.067154  0.032734 -0.001850  \n",
       "30  0.172890  0.140145  0.108115  0.071662  0.034874 -0.001552  \n",
       "31  0.185433  0.150109  0.115058  0.076456  0.037181 -0.001226  \n",
       "32  0.198763  0.160741  0.122464  0.081560  0.039671 -0.000875  \n",
       "33  0.212898  0.172062  0.130370  0.086999  0.042366 -0.000505  \n",
       "34  0.227853  0.184090  0.138818  0.092803  0.045284 -0.000122  \n",
       "35  0.243630  0.196830  0.147854  0.099005  0.048447  0.000266  \n",
       "36  0.260226  0.210283  0.157528  0.105641  0.051875  0.000650  \n",
       "37  0.277622  0.224432  0.167897  0.112751  0.055589  0.001016  \n",
       "38  0.295787  0.239253  0.179021  0.120379  0.059601  0.001349  \n",
       "39  0.314950  0.255041  0.190743  0.128882  0.064241  0.001516  \n",
       "40  0.335257  0.272007  0.203454  0.137469  0.069829  0.001522  \n",
       "41  0.356845  0.289218  0.216321  0.146316  0.075394  0.000894  \n",
       "42  0.379348  0.306534  0.229513  0.155739  0.080870 -0.000290  \n",
       "43  0.402199  0.324334  0.243602  0.165839  0.086714 -0.001719  \n",
       "44  0.425178  0.342535  0.258629  0.176647  0.092895 -0.003434  \n",
       "45  0.448186  0.360920  0.274655  0.188158  0.099288 -0.005547  \n",
       "\n",
       "[46 rows x 101 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85404e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"predictionlstm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a2d21634",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv(\"errorlstm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "093b9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual.to_csv(\"actual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917c210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
